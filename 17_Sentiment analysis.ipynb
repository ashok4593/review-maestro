{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('reviews.csv',usecols=['review_id','review','rating','sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11321 entries, 0 to 11320\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review_id  11321 non-null  object\n",
      " 1   review     11321 non-null  object\n",
      " 2   rating     11321 non-null  int64 \n",
      " 3   sentiment  10601 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 353.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Droping reviews with missing sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning reviews "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting emojis and emoticons to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: emot in e:\\anacondauser\\lib\\site-packages (3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emot --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iâ€™ve used Evernote daily since 2013 to journal, organize work streams and plan effective projects. I often joke that it is my external brain because the way I have it categorically organized encompasses most facets of my life. The flexible hierarchy available thru notes, notebooks and tags works well for me. Syncing across devices was also a game changer for me. Truthfully, my biggest fear is that Evernote would ever go away! Please donâ€™t. Yours could forever, Evernote. ðŸ’Œ'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[7,'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emot.emo_unicode import UNICODE_EMOJI\n",
    "def convert_emoji(text):\n",
    "    for emot in UNICODE_EMOJI:\n",
    "        text = text.replace(emot, \"_\".join(UNICODE_EMOJI[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['review'] = dataset['review'].apply(convert_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iâ€™ve used Evernote daily since 2013 to journal, organize work streams and plan effective projects. I often joke that it is my external brain because the way I have it categorically organized encompasses most facets of my life. The flexible hierarchy available thru notes, notebooks and tags works well for me. Syncing across devices was also a game changer for me. Truthfully, my biggest fear is that Evernote would ever go away! Please donâ€™t. Yours could forever, Evernote. love_letter'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[7,'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, Iâ€™d like word in computer, you create a document, and you print it, I mean the basic. On mobile..nope. Itâ€™s like paint but blue themed. I mean there can be a lot of improvements and fixes. Also the app crashed my tablet like 3 times before even finishing the download. Ok other then that, I honestly didnâ€™t like it. For a document itâ€™s good you got the basics. But it isnâ€™t enough like... ok maybe on my phone it might be bad and all that but i mean meh. But on the tablet (seeing the pictures in the App Store) itâ€™s good I mean the same for computer but a little bit laggy and bugs and crashes. There can be a LOOT of diffÃ©rents if you could just work on it better.Ok. As an app. I can say meh. Not bad. Just less settings in the mob and tabs. But other then that crashes. Fix these and make the layout better :) also the app takes a lot to download and a lot to start it up. Make this a generator instead of a non deleting paper for like ever. Thanks for reading'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[128,'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emot.emo_unicode import EMOTICONS_EMO\n",
    "def convert_emoticons(text):\n",
    "    for emot in EMOTICONS_EMO:\n",
    "        text = text.replace(emot, \"_\".join(EMOTICONS_EMO[emot].replace(\",\",\"\").split()))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['review'] = dataset['review'].apply(convert_emoticons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, Iâ€™d like word in computer, you create a document, and you print it, I mean the basic. On mobile..nope. Itâ€™s like paint but blue themed. I mean there can be a lot of improvements and fixes. Also the app crashed my tablet like 3 times before even finishing the download. Ok other then that, I honestly didnâ€™t like it. For a document itâ€™s good you got the basics. But it isnâ€™t enough like... ok maybe on my phone it might be bad and all that but i mean meh. But on the tablet (seeing the pictures in the App Store) itâ€™s good I mean the same for computer but a little bit laggy and bugs and crashes. There can be a LOOT of diffÃ©rents if you could just work on it better.Ok. As an app. I can say meh. Not bad. Just less settings in the mob and tabs. But other then that crashes. Fix these and make the layout better Happy_face_or_smiley also the app takes a lot to download and a lot to start it up. Make this a generator instead of a non deleting paper for like ever. Thanks for reading'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[128,'review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace a sequence of repeated characters with two characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I love Monopoly and when this game is working it is soooooooooo much fun. But it freezes way too often. If it was simply a free game with in App Purchases, I would not mind at all. But I pay for the fastest fiber optics network around, and even with that connection I can't normally make it through an online game. Every time I try it freezes at some point and I can't continue playing. For a game you have to pay $4 just to play normally, I really think that's a factor that needs to be addressed. But Pass and Play is a fun way to pass time when you're traveling with someone or are waiting on an appointment, and playing the AI can still be a fun experience as well. But please for the price you charge get the online play feature tuned up. Even if you toned down the graphics to decrease the chance of it freezing I'm sure people would still love to play!\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'(.)\\1*')  \n",
    "def reduce_sequence_word(word):\n",
    "     return ''.join([match.group()[:2] if len(match.group()) > 2 else match.group() for match in pattern.finditer(word)]) \n",
    "def reduce_sequence_review(review):\n",
    "     return ' '.join([reduce_sequence_word(word) for word in review.split(' ')])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['review'] = dataset['review'].apply(reduce_sequence_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I love Monopoly and when this game is working it is soo much fun. But it freezes way too often. If it was simply a free game with in App Purchases, I would not mind at all. But I pay for the fastest fiber optics network around, and even with that connection I can't normally make it through an online game. Every time I try it freezes at some point and I can't continue playing. For a game you have to pay $4 just to play normally, I really think that's a factor that needs to be addressed. But Pass and Play is a fun way to pass time when you're traveling with someone or are waiting on an appointment, and playing the AI can still be a fun experience as well. But please for the price you charge get the online play feature tuned up. Even if you toned down the graphics to decrease the chance of it freezing I'm sure people would still love to play!\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[-1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing non alphabetic words, stop words and  word stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "# This is stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "#this is lemmatization\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "stopwords_to_consider = []\n",
    "stopwords_to_consider = ['on','off','no','nor','not',\"don't\",'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "def text_preprocessor(review):\n",
    "    processed_r = re.sub('[^a-zA-z]',' ',review)\n",
    "    processed_r = processed_r.lower()\n",
    "    processed_r = processed_r.split()\n",
    "    all_stopwords = [w for w in stopwords.words('english') if not w in stopwords_to_consider]\n",
    "    # This is stemming\n",
    "    ps = PorterStemmer()\n",
    "    processed_r = [ps.stem(word) for word in processed_r if not word in set(all_stopwords)]\n",
    "    #this is lemmatization\n",
    "    #lemmatizer = WordNetLemmatizer()\n",
    "    #processed_r = [lemmatizer.lemmatize(word) for word in processed_r if not word in set(all_stopwords)]\n",
    "    return ' '.join(processed_r)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['review'] = dataset['review'].apply(text_preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset['review'].str.len() > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c9274c0a-a120-4e09-816b-7a8ba3a16634</td>\n",
       "      <td>new version thing entir differ aesthet thing t...</td>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>506230e3-cc98-4233-be40-89e52d53990c</td>\n",
       "      <td>lot peopl use word standard run problem use ev...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69d44a5e-218f-4f55-8a99-6cca55d43ca1</td>\n",
       "      <td>origin skeptic on pay on todo list app come re...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3d0b634c-d402-47e8-ba7d-bf6209fed826</td>\n",
       "      <td>use go app note take year problem write use re...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7310f23f-06c2-447d-aafd-81b29765169d</td>\n",
       "      <td>use year tag capabl uniqu integr across platfo...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              review_id  \\\n",
       "0  c9274c0a-a120-4e09-816b-7a8ba3a16634   \n",
       "2  506230e3-cc98-4233-be40-89e52d53990c   \n",
       "3  69d44a5e-218f-4f55-8a99-6cca55d43ca1   \n",
       "4  3d0b634c-d402-47e8-ba7d-bf6209fed826   \n",
       "5  7310f23f-06c2-447d-aafd-81b29765169d   \n",
       "\n",
       "                                              review  rating sentiment  \n",
       "0  new version thing entir differ aesthet thing t...       3  positive  \n",
       "2  lot peopl use word standard run problem use ev...       1  negative  \n",
       "3  origin skeptic on pay on todo list app come re...       5  positive  \n",
       "4  use go app note take year problem write use re...       1  negative  \n",
       "5  use year tag capabl uniqu integr across platfo...       5  positive  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,1:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['new version thing entir differ aesthet thing thing much minimalist thing seem lot ui bloat not quit sure design award came',\n",
       "        3],\n",
       "       ['lot peopl use word standard run problem use everi updat problem format everyth on page partli on page on part partli on page forth throughout page document tri call support reach someon bare speak english tell happen say chang someth document ye close document yesterday format correctli updat app today open wrong must middl night switch appl page thank peopl work realli hard make work realli great effort part not fun issu happen on macbook ipad point set someth exactli want simpl updat chang everyth nonsens',\n",
       "        1],\n",
       "       ['origin skeptic on pay on todo list app come realiz great invest abl creat mani differ header project categor differ class take no longer use physic planner app take care problem eas use simplic great function led rate app star definit worth price',\n",
       "        5],\n",
       "       ...,\n",
       "       ['game great pass time line wait place order favorit dinner restaur littl someth everyon young old haven use video mode much say realli review aspect sorri otherwis fun enjoy game fun deck',\n",
       "        5],\n",
       "       ['ok play minecraft year love even though add new updat minecraft feel haven ad thing realli would make minecraft wayi better love dolphin turtl couldn add like perhap turkey peacock know easili get mod thing cost money also think add dog breed weren wolf would lot dog like mayb could huski pug pomeranian shiba chiwawa great dane great dog breed could dog get color wolf tame like huski would white wolf great dane could brown wolf think also abl tame polar bear turtl dolphin tame saddl ride also think fish bowl thing catch fish put fish bowl depend on amount glass use get differ size fish bowl hope read review mojang could help minecraft peopl play game aubre mojang happy_face_or_smileygrinning_fac',\n",
       "        3],\n",
       "       ['love monopoli game work soo much fun freez way often simpli free game app purchas would not mind pay fastest fiber optic network around even connect normal make onlin game everi time tri freez point continu play game pay play normal realli think factor need address pass play fun way pass time travel someon wait on appoint play ai still fun experi well pleas price charg get onlin play featur tune even tone graphic decreas chanc freez sure peopl would still love play',\n",
       "        5]], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding the dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative', 'positive', ..., 'negative', 'positive',\n",
       "       'negative'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'positive']\n",
      "[1 0 1 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(le.classes_)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "preprocess = ColumnTransformer(transformers=[('vectorize', TfidfVectorizer(ngram_range=(1,2),max_features = 3000),0)],remainder='passthrough')\n",
    "X = preprocess.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3001"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        5.        ],\n",
       "       [0.        , 0.11219596, 0.        , ..., 0.        , 0.        ,\n",
       "        4.        ],\n",
       "       [0.        , 0.08591083, 0.08467555, ..., 0.        , 0.        ,\n",
       "        2.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        5.        ],\n",
       "       [0.16847719, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        5.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        3.        ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy and confustion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[899 431]\n",
      " [534 784]]\n",
      "The accuracy of model is: 63.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "cm =confusion_matrix(y_test,y_pred)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(cm)\n",
    "print(\"The accuracy of model is: {:0.2f}\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Average Accuracy of model is: 63.49 %\n",
      "With a Standard Deviation of: 1.84 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print(\"The Average Accuracy of model is: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"With a Standard Deviation of: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision recall and f-measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision of model is: 64.53\n",
      "The recall of model is: 59.48\n",
      "The f-measure of model is: 61.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "p_score = precision_score(y_test,y_pred)\n",
    "r_score = recall_score(y_test,y_pred)\n",
    "f_score = f1_score(y_test,y_pred)\n",
    "print(\"The precision of model is: {:0.2f}\".format(p_score*100))\n",
    "print(\"The recall of model is: {:0.2f}\".format(r_score*100))\n",
    "print(\"The f-measure of model is: {:0.2f}\".format(f_score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model - Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy and confustion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "cm =confusion_matrix(y_test,y_pred)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(cm)\n",
    "print(\"The accuracy of model is: {:0.2f}\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print(\"The Average Accuracy of model is: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"With a Standard Deviation of: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision recall and f-measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "p_score = precision_score(y_test,y_pred)\n",
    "r_score = recall_score(y_test,y_pred)\n",
    "f_score = f1_score(y_test,y_pred)\n",
    "print(\"The precision of model is: {:0.2f}\".format(p_score*100))\n",
    "print(\"The recall of model is: {:0.2f}\".format(r_score*100))\n",
    "print(\"The f-measure of model is: {:0.2f}\".format(f_score*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
